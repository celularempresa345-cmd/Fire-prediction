{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/celularempresa345-cmd/Fire-prediction/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Parámetros\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH = 8   # pequeño por pocos datos\n",
        "DATASET_DIR = \"/content/drive/MyDrive/dataset\"\n",
        "CLASSES = ['Baja', 'Moderada', 'Alta']\n"
      ],
      "metadata": {
        "id": "Tdd3dyg__x4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6kinZGuWe71U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_hsv(img_path, img_size=IMG_SIZE):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  # convertir a HSV\n",
        "    img = cv2.resize(img, img_size)\n",
        "    img = img / 255.0\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "jEYYvGp7_yqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    validation_split=0.2,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    brightness_range=[0.6, 1.4],\n",
        "    zoom_range=0.25,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=lambda x: x/255.0\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATASET_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH,\n",
        "    class_mode='categorical',\n",
        "    classes=CLASSES,\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    DATASET_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH,\n",
        "    class_mode='categorical',\n",
        "    classes=CLASSES,\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "M9jkJQe8_0ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "\n",
        "# Congelar todas las capas convolucionales\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Capas densas finales\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.6)(x)  # dropout alto por pocos datos\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "predictions = Dense(len(CLASSES), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "ZF8_llHT_2Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=30,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "id": "OoVMqtTF_4dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def color_features(img_path):\n",
        "    \"\"\"\n",
        "    Calcula porcentaje de píxeles que caen en verde, naranja y café/blanco.\n",
        "    img_path: ruta de la imagen\n",
        "    devuelve: array [verde, naranja, cafe/blanco]\n",
        "    \"\"\"\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Verde puro (Baja)\n",
        "    lower_green = np.array([35, 50, 50])\n",
        "    upper_green = np.array([85, 255, 255])\n",
        "    mask_green = cv2.inRange(img, lower_green, upper_green)\n",
        "    green_ratio = np.sum(mask_green > 0) / (img.shape[0]*img.shape[1])\n",
        "\n",
        "    # Naranja/amarillo (Moderada)\n",
        "    lower_orange = np.array([10, 50, 50])\n",
        "    upper_orange = np.array([30, 255, 255])\n",
        "    mask_orange = cv2.inRange(img, lower_orange, upper_orange)\n",
        "    orange_ratio = np.sum(mask_orange > 0) / (img.shape[0]*img.shape[1])\n",
        "\n",
        "    # Café oscuro/blanco (Alta)\n",
        "    lower_brown = np.array([0, 0, 50])\n",
        "    upper_brown = np.array([20, 255, 200])\n",
        "    mask_brown = cv2.inRange(img, lower_brown, upper_brown)\n",
        "    white_ratio = np.sum(img[:,:,2] > 200) / (img.shape[0]*img.shape[1])  # píxeles muy claros\n",
        "    high_ratio = np.sum(mask_brown > 0)/ (img.shape[0]*img.shape[1]) + white_ratio\n",
        "\n",
        "    return np.array([green_ratio, orange_ratio, high_ratio])\n"
      ],
      "metadata": {
        "id": "DmU_6S4K_8z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image_color(img_path):\n",
        "    # 1️⃣ Características MobileNetV2\n",
        "    img = load_image_hsv(img_path)\n",
        "    img_array = np.expand_dims(img, axis=0)\n",
        "    pred_cnn = model.predict(img_array)[0]\n",
        "\n",
        "    # 2️⃣ Características de color explícitas\n",
        "    color_feats = color_features(img_path)\n",
        "\n",
        "    # 3️⃣ Combinación ponderada CNN + color\n",
        "    combined = 0.6*pred_cnn + 0.4*color_feats\n",
        "    class_idx = np.argmax(combined)\n",
        "    class_label = CLASSES[class_idx]\n",
        "    confidence = combined[class_idx]\n",
        "\n",
        "    # Mostrar imagen\n",
        "    img_display = cv2.cvtColor((img*255).astype(np.uint8), cv2.COLOR_HSV2RGB)\n",
        "    plt.imshow(img_display)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"{class_label} ({confidence*100:.2f}%)\")\n",
        "    plt.show()\n",
        "\n",
        "    return class_label, confidence\n"
      ],
      "metadata": {
        "id": "PenU6jPw_9TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    label, conf = predict_image_color(filename)\n",
        "    print(f\"Imagen: {filename} -> {label} ({conf*100:.2f}%)\")\n"
      ],
      "metadata": {
        "id": "NHO-Qr4N__OE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
